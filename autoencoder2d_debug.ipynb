{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "cmap = matplotlib.colormaps.get('tab10').colors\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from gen_autoencoder_dataset import AutoencoderDataset\n",
    "from torcheval.metrics import BinaryAUROC\n",
    "from tqdm import trange"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from pytest import mark\n",
    "rng = np.random.default_rng()\n",
    "import os\n",
    "import torch_geometric as tg\n",
    "import torch\n",
    "from tqdm import trange\n",
    "from scipy.spatial import KDTree\n",
    "import networkx as nx\n",
    "\n",
    "class AutoencoderDataset(tg.data.Dataset):\n",
    "    '''\n",
    "    This class bundles the creation and saving as well as loading of a dataset of 3D graphs. If an instance is created, the class will \n",
    "    check in root directory if the dataset is already processed. If not, the process() method will be called. Furthermore, the\n",
    "    dataset will be loaded. If the dataset shall be calculated again, the process() method must be called explicitely.\n",
    "    '''\n",
    "    def __init__(self, root, n_graphs_per_type=100, transform=None, pre_transform=None):\n",
    "        '''\n",
    "        Args:\n",
    "        - root (str): The directory where the dataset should be stored, divided into processed and raw dirs\n",
    "        '''\n",
    "        self.root = root\n",
    "        self.n_graphs_per_type = n_graphs_per_type\n",
    "        super().__init__(root, transform, pre_transform)\n",
    "        \n",
    "    @property\n",
    "    def raw_file_names(self):\n",
    "        '''\n",
    "        If this file exists in the raw directory, the download will be skipped. Download not implemented.\n",
    "        '''\n",
    "        return 'raw.txt'\n",
    "    \n",
    "    @property\n",
    "    def processed_file_names(self):\n",
    "        '''\n",
    "        If this file exists in the processed directory, processing will be skipped. \n",
    "        Note: This does smh not work, therefore files are ATM recalculated every time.\n",
    "        '''\n",
    "        return ['data_00000.pt']\n",
    "    \n",
    "    def download(self):\n",
    "        '''\n",
    "        Download not implemented.\n",
    "        '''\n",
    "        pass\n",
    "    \n",
    "    def len(self):\n",
    "        '''\n",
    "        Returns the number of graphs in the dataset.\n",
    "        '''\n",
    "        return len([f for f in os.listdir(os.path.join(self.root, 'processed')) if f.startswith('data')])\n",
    "    \n",
    "    def get(self, idx):\n",
    "        '''\n",
    "        Returns the graph at index idx. \n",
    "        '''\n",
    "        data = torch.load(os.path.join(self.processed_dir, 'data_{:05d}.pt'.format(idx)))\n",
    "        return data\n",
    "    \n",
    "    def process(self):\n",
    "        '''\n",
    "        Here creation, processing and saving of the dataset happens. \n",
    "        '''\n",
    "        \n",
    "        lattice_types = {\n",
    "            0: {'name': 'mP', 'nodes': self._get_P_nodes, 'binding_angle':   0, 'scale': [0, 0]},\n",
    "            1: {'name': 'oP', 'nodes': self._get_P_nodes, 'binding_angle':  90, 'scale': [0, 0]},\n",
    "            2: {'name': 'oC', 'nodes': self._get_C_nodes, 'binding_angle':  90, 'scale': [0, 0]},\n",
    "            3: {'name': 'tP', 'nodes': self._get_P_nodes, 'binding_angle':  90, 'scale': [1, 1]},\n",
    "            4: {'name': 'hP', 'nodes': self._get_P_nodes, 'binding_angle': 120, 'scale': [1, 1]}\n",
    "        }\n",
    "\n",
    "        \n",
    "        for n in trange(self.n_graphs_per_type * 14):\n",
    "            # Get graph features:\n",
    "            pos, edge_index, label = self._process_lattice(lattice_types[n % 14])\n",
    "            label = np.expand_dims(label, axis=1)\n",
    "            node_attr = self._get_node_attr(pos, edge_index)\n",
    "            # node_attr = pos\n",
    "            #edge_attr = self._get_edge_attr(pos, edge_index)\n",
    "            \n",
    "            # Create data object:\n",
    "            data = tg.data.Data(x          = torch.tensor(node_attr, dtype=torch.float), \n",
    "                                edge_index = torch.tensor(edge_index, dtype=torch.int64), \n",
    "                                y          = torch.tensor(label, dtype=torch.float), \n",
    "                                pos        = torch.tensor(pos, dtype=torch.float))\n",
    "            # Save data object:\n",
    "            torch.save(data, os.path.join(self.processed_dir, 'data_{:05d}.pt'.format(n)))\n",
    "\n",
    "class planeGraphGenerator():\n",
    "    def __init__(self, size=(6,6)):\n",
    "        '''\n",
    "        Args:\n",
    "        - size (tuple): The size of the lattice in x,y direction. The lattice will be size[0] x size[1] large.\n",
    "        '''\n",
    "        self.size = size\n",
    "        self.lattice_types = {\n",
    "            0: {'name': 'mP', 'nodes': self._get_P_nodes, 'binding_angle':   0, 'scale': [0, 0]},\n",
    "            1: {'name': 'oP', 'nodes': self._get_P_nodes, 'binding_angle':  90, 'scale': [0, 0]},\n",
    "            2: {'name': 'oC', 'nodes': self._get_C_nodes, 'binding_angle':  90, 'scale': [0, 0]},\n",
    "            3: {'name': 'tP', 'nodes': self._get_P_nodes, 'binding_angle':  90, 'scale': [1, 1]},\n",
    "            4: {'name': 'hP', 'nodes': self._get_P_nodes, 'binding_angle': 120, 'scale': [1, 1]}\n",
    "        }\n",
    "        \n",
    "    def _get_P_nodes(self, angle=90):\n",
    "        '''\n",
    "        Get the nodes of a primitive lattice.\n",
    "        '''\n",
    "        scaling = np.sin(np.radians(angle))\n",
    "        vec1 = np.arange(0,self.size[0])\n",
    "        vec2 = np.arange(0,self.size[1])*scaling\n",
    "        a, b = np.meshgrid(vec1,vec2)\n",
    "        nodes = np.stack([a,b],axis=-1) # Stack them in a new axis\n",
    "        nodes = np.reshape(nodes, (-1, 2)) # Reshape to an arr of nodes with shape (#nodes, 2)\n",
    "        return nodes\n",
    "\n",
    "    def _get_C_nodes(self):\n",
    "        '''\n",
    "        Get the nodes of a centred lattice.\n",
    "        '''\n",
    "        P = self._get_P_nodes()\n",
    "        extra = P + np.array([0.5,0.5])\n",
    "        return np.row_stack((P, extra))\n",
    "    \n",
    "\n",
    "    def _process_lattice(self, arg_dict):\n",
    "        '''\n",
    "        Method that processes a lattice of a given type. The method is called with a dictionary holding parameters for one of the lattice types. It contains the following keys:\n",
    "            - name: The name of the lattice type\n",
    "            - nodes: The method to get the fitting fundamental lattice nodes\n",
    "            - binding_angle: binding angle alpha of the lattice type. angle are in degrees. 0° means to generate a independent random angle (0,180)°\n",
    "            - scale: A list of scaling factors [x,y] for the lattice type. 0 means to generate a random scaling factor (0,2)\n",
    "        '''\n",
    "        # Get lattice angles\n",
    "        angle = arg_dict['binding_angle']\n",
    "        if angle == 0:\n",
    "            angle = rng.uniform(46,89,1)\n",
    "            \n",
    "        # Get the fundamental lattice nodes\n",
    "        if arg_dict['name'] in ['hP']:\n",
    "            # For hP lattice we need to give the angle to the nodes method so that sheared connections are equally long\n",
    "            nodes = arg_dict['nodes'](angle)\n",
    "        else:\n",
    "            nodes = arg_dict['nodes']()\n",
    "        nodes = self._shear_nodes(nodes, angle)\n",
    "        # Find random scale and apply gaussian noise to the lattice accordingly\n",
    "        scale = np.array(arg_dict['scale'])\n",
    "        scale = np.where(scale == 0, rng.uniform(0.3,3,2), scale)\n",
    "        noise_level = 0.05 / scale  # At this step we scale the noise down, so that the scaling later on does not affect the noise level\n",
    "        #nodes += rng.normal(0, noise_level, nodes.shape)\n",
    "        \n",
    "        nodes, labels = self._displace_node(nodes)\n",
    "        # Find the connections between the nodes in a given radius\n",
    "        cons= self._get_cons_in_radius(nodes, 1.3+np.mean(noise_level))\n",
    "        # Apply the saved scaling\n",
    "        nodes *= scale\n",
    "        \n",
    "        # Add defects to the lattice\n",
    "        #nodes, cons, labels = self._add_defects(nodes, cons, labels)\n",
    "        return nodes, cons, labels\n",
    "\n",
    "    def _displace_node(self, nodes):\n",
    "        '''\n",
    "        Method that dislaces one random node in the lattice by a random amount. Returns the new nodes and the label for classification. \n",
    "        The label is a one hot encoded array of shape (len(nodes)) where 1 markes the index od the displaced node.\n",
    "        '''\n",
    "        # Get random node and displacement\n",
    "        node_ind = rng.integers(0, len(nodes))\n",
    "        displacement = rng.normal(0, 1, 2)\n",
    "        # Assert that the displacement does not move the node out of the lattice (roughly)\n",
    "        while np.any(nodes[node_ind] + displacement < np.min(nodes, axis=0)) or np.any(nodes[node_ind] + displacement > np.max(nodes, axis=0)):\n",
    "            displacement = rng.normal(0, 1, 2)\n",
    "        # Displace node, get label\n",
    "        nodes[node_ind] += displacement\n",
    "        labels = np.zeros(len(nodes))\n",
    "        labels[node_ind] = 1\n",
    "        return nodes, labels\n",
    "    \n",
    "    def _get_cons_in_radius(self, nodes, radius):\n",
    "        '''\n",
    "        Get the connections in a radius as well as the total number of cons for each node.\n",
    "        '''\n",
    "        tree = KDTree(nodes)\n",
    "        cons = tree.query_pairs(radius, output_type='ndarray', p=2)\n",
    "        cons = cons.T\n",
    "        cons = np.column_stack((cons, cons[::-1])) # Add the reverse connections\n",
    "        return cons\n",
    "\n",
    "    def _shear_nodes(self, nodes, binding_angle):\n",
    "        '''\n",
    "        Shear nodes by binding angle.\n",
    "        '''\n",
    "        delta = np.tan(np.radians(binding_angle))\n",
    "        assert not np.any(delta == 0), 'Binding angle cannot be 0'\n",
    "        nodes = nodes.astype(float)\n",
    "        nodes = nodes + np.stack((nodes[:,1]/delta, np.zeros_like(nodes[:,1])), axis=1)\n",
    "        return nodes\n",
    "\n",
    "    def _add_defects(self, nodes, edge_index, labels):\n",
    "        '''\n",
    "        Method that adds up to 10% of random defects (i.e. missing nodes) to the lattice. Should be called after _get_*_graph() but before\n",
    "        _get_edge_attr() and _get_node_attr().\n",
    "        '''\n",
    "        # Draw up to 10% of unique random indices for nodes to be removed\n",
    "        drop_indices = rng.choice(np.arange(len(nodes)), rng.integers(len(nodes)//10), replace=False)\n",
    "        # Remove the nodes and labels\n",
    "        nodes = np.delete(nodes, drop_indices, axis=0)\n",
    "        labels = np.delete(labels, drop_indices, axis=0)\n",
    "        # Delete every connection that refers to a removed node\n",
    "        edge_index = np.delete(edge_index, np.where(np.isin(edge_index, drop_indices))[1], axis=1)\n",
    "        \n",
    "        # As edge_index refers to the original node indices, we need to adjust the indices of most connections\n",
    "        # For this we create a mapping from old indices to new indices\n",
    "        old_to_new = np.arange(len(nodes) + len(drop_indices))  # Start with an array of original indices; [0,1,2,3,4,5,...]\n",
    "        old_to_new[drop_indices] = -1  # Mark the indices of the nodes to be deleted; eg. drop_indices = [1,3] -> [0,-1,2,-1,4,5,...]\n",
    "        old_to_new = np.cumsum(old_to_new != -1) - 1  # Create a cumulative sum array; cumsum([True, False, True, False, True, True,...]) -1 -> [1,1,2,2,3,4,...] -1 -> [0,0,1,1,2,3,...]\n",
    "        \n",
    "        # # Update edge indices to reflect new node indices through broadcasting\n",
    "        edge_index = old_to_new[edge_index]\n",
    "        return nodes, edge_index, labels\n",
    "        \n",
    "    def _get_node_attr(self,nodes,cons):\n",
    "        '''\n",
    "        Method that returns the node attributes for each node in the graph. Should be called after creating the graph and adding defects.\n",
    "        The node attributes have the shape (num_nodes, num_node_features). For each node, the node features are the following:\n",
    "        - The bond orientational order parameters for l=4,6,8,10 (4 features)\n",
    "        '''\n",
    "        G = nx.Graph()\n",
    "        G.add_edges_from(cons.T)\n",
    "        boo_arr = np.zeros((len(nodes), 4), dtype=complex)\n",
    "        \n",
    "        for i in range(len(nodes)):\n",
    "            # iterate over all nodes, get their neighbors\n",
    "            neighbors = list(G.neighbors(i))\n",
    "            if len(neighbors) == 0:\n",
    "                # no neighbors, return 0\n",
    "                boo_arr[i] = np.zeros(4)\n",
    "                continue\n",
    "            # calculate the bond orientational order parameters\n",
    "            boo_ = np.zeros(4, dtype=complex)\n",
    "            for n in neighbors:\n",
    "                angle = np.arctan2(nodes[n,1] - nodes[i,1], nodes[n,0] - nodes[i,0])\n",
    "                boo_ += np.array([np.exp(1j*4*angle), np.exp(1j*6*angle), np.exp(1j*8*angle), np.exp(1j*10*angle)])   \n",
    "            boo_arr[i] = np.abs(boo_ / len(neighbors)) \n",
    "            \n",
    "        return boo_arr.astype(float)\n",
    "        \n",
    "    \n",
    "    def _get_edge_attr(self,nodes,cons):\n",
    "        '''\n",
    "        Method that returns the edge attributes for each edge in the graph. Should be called after creating the graph and adding defects.\n",
    "        Returns an array of shape (len(edge_index[0])= #Edges, 2) with the entries [dx,dy] for each edge.\n",
    "        '''\n",
    "        # Get the edge vectors for each edge\n",
    "        edge_vectors = nodes[cons[0]] - nodes[cons[1]]\n",
    "        return edge_vectors\n",
    "    \n",
    "    \n",
    "\n",
    "\n",
    "def plot(nodes, cons, labels=None):\n",
    "    '''\n",
    "    Plot the graph.\n",
    "    '''\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.scatter(nodes[:,0], nodes[:,1], c='black')\n",
    "    for con in cons.T:\n",
    "        ax.plot(nodes[con,0], nodes[con,1], c='black')\n",
    "    if labels is not None:\n",
    "        ax.plot(nodes[labels==1,0], nodes[labels==1,1], c='red', markersize=10, marker='o', linestyle='None')\n",
    "    ax.set_aspect('equal')\n",
    "    ax.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\steph\\AppData\\Local\\Temp\\ipykernel_4776\\2384156452.py:246: ComplexWarning: Casting complex values to real discards the imaginary part\n",
      "  return boo_arr.astype(float)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.96871547, 0.36738165, 0.87681934, 0.58670755],\n",
       "       [0.96762905, 0.12756135, 0.87520135, 0.23486685],\n",
       "       [0.96762905, 0.12756135, 0.87520135, 0.23486685],\n",
       "       [0.96762905, 0.12756135, 0.87520135, 0.23486685],\n",
       "       [0.96762905, 0.12756135, 0.87520135, 0.23486685],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.96859722, 0.13280761, 0.88001772, 0.02134662],\n",
       "       [0.95983062, 0.23354653, 0.84354343, 0.30554217],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95104129, 0.50322302, 0.81005296, 0.34496871],\n",
       "       [0.48104482, 0.0526056 , 0.24233218, 0.28258975],\n",
       "       [0.95104129, 0.50322302, 0.81005296, 0.34496871],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95983062, 0.23354653, 0.84354343, 0.30554217],\n",
       "       [0.8856006 , 0.19793518, 0.62625502, 0.15248852],\n",
       "       [0.95349325, 0.32826588, 0.82186655, 0.16357692],\n",
       "       [0.79422425, 0.08606631, 0.60012513, 0.27677252],\n",
       "       [0.95392717, 0.44758342, 0.82073028, 0.38441885],\n",
       "       [0.95814037, 0.26706692, 0.83794194, 0.17952011],\n",
       "       [0.83840437, 0.16957211, 0.5250229 , 0.37668289],\n",
       "       [0.97211409, 0.14789731, 0.8931412 , 0.06933458],\n",
       "       [0.88890548, 0.29315136, 0.6160474 , 0.38456302],\n",
       "       [0.96762905, 0.12756135, 0.87520135, 0.23486685],\n",
       "       [0.96871547, 0.36738165, 0.87681934, 0.58670755]])"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "g = planeGraphGenerator()\n",
    "nodes, cons, labels = g._process_lattice(g.lattice_types[0])\n",
    "g._get_node_attr(nodes, cons)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
