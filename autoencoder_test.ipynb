{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "cmap = matplotlib.colormaps.get('tab10').colors\n",
    "import torch\n",
    "import torch_geometric as tg\n",
    "from gen_autoencoder_dataset import AutoencoderDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/420 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 420/420 [00:02<00:00, 142.88it/s]\n"
     ]
    }
   ],
   "source": [
    "n = 30\n",
    "dataset = AutoencoderDataset(root='autoencoder_graphs', n_graphs_per_type=n)\n",
    "dataset.process()\n",
    "train_loader = tg.loader.DataLoader(dataset[:n*12], batch_size=16, shuffle=True)\n",
    "test_loader = tg.loader.DataLoader(dataset[n*12:], batch_size=16, shuffle=True)\n",
    "train_loader.dataset[2]\n",
    "device= 'cuda' if torch.cuda.is_available() else 'cpu'\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## New idea: Do on my own"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dominant(\n",
      "  (encoder): ModuleList(\n",
      "    (0): GCNConv(3, 3)\n",
      "    (1): GCNConv(3, 2)\n",
      "  )\n",
      "  (attr_decoder): ModuleList(\n",
      "    (0): GCNConv(2, 3)\n",
      "    (1): GCNConv(3, 3)\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "num_features = dataset.num_features\n",
    "alpha = 0.5 # weight of the attribute loss\n",
    "\n",
    "\n",
    "class dominant(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super(dominant, self).__init__()\n",
    "        self.encoder = torch.nn.ModuleList()\n",
    "        self.encoder.append(tg.nn.GCNConv(num_features, 3))\n",
    "        self.encoder.append(tg.nn.GCNConv(3, 2))\n",
    "        \n",
    "        \n",
    "        self.attr_decoder =torch.nn.ModuleList()\n",
    "        self.attr_decoder.append(tg.nn.GCNConv(2, 3))\n",
    "        self.attr_decoder.append(tg.nn.GCNConv(3, num_features))\n",
    "    def forward(self, x, edge_index):\n",
    "        # encoder\n",
    "        #print(x.shape, edge_index.shape)\n",
    "        z = self.encoder[0](x, edge_index).relu()\n",
    "        z = self.encoder[1](z, edge_index).relu()\n",
    "        # decoder\n",
    "        adj = torch.sigmoid(z @ z.T) # structure decoder\n",
    "        \n",
    "        x_ = self.attr_decoder[0](z, edge_index).relu()\n",
    "        x_ = self.attr_decoder[1](x_, edge_index).relu() # attribute decoder\n",
    "        return x_, adj\n",
    "    \n",
    "        \n",
    "        \n",
    "model = dominant()\n",
    "model.to(device)\n",
    "print(model)\n",
    "\n",
    "def loss_func(x, x_, adj, adj_):\n",
    "    # print(f\"x shape: {x.shape}, x_ shape: {x_.shape}\")\n",
    "    # print(f\"edge_index shape: {edge_index.shape}, adj shape: {adj.shape}\")\n",
    "    #edge_index = edge_index.type(torch.float)\n",
    "    adj = adj.type(torch.float)\n",
    "    return alpha * torch.nn.functional.mse_loss(x, x_) + (1-alpha) * torch.nn.functional.mse_loss(adj, adj_)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Training Loss: 8.2346\n",
      "Epoch: 002, Training Loss: 8.1124\n",
      "Epoch: 003, Training Loss: 7.9121\n",
      "Epoch: 004, Training Loss: 7.2183\n",
      "Epoch: 005, Training Loss: 6.4234\n",
      "Epoch: 006, Training Loss: 5.7183\n",
      "Epoch: 007, Training Loss: 5.1464\n",
      "Epoch: 008, Training Loss: 4.9318\n",
      "Epoch: 009, Training Loss: 4.7343\n",
      "Epoch: 010, Training Loss: 4.5434\n"
     ]
    }
   ],
   "source": [
    "# training:\n",
    "epochs = 10\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    avg_loss = 0\n",
    "    for data in loader:\n",
    "        data = data.to(device)\n",
    "        x_, adj = model.forward(data.x, data.edge_index)\n",
    "    \n",
    "        loss = loss_func(data.x, x_, tg.utils.to_dense_adj(data.edge_index)[0], adj)\n",
    "        avg_loss += loss.item()\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    return avg_loss / len(loader)\n",
    "for epoch in range(1, epochs+1):\n",
    "    loss = train(train_loader)\n",
    "    print('Epoch: {:03d}, Training Loss: {:.4f}'.format(epoch, loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
