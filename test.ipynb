{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "rng = np.random.default_rng()\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "%matplotlib widget\n",
    "cmap = matplotlib.colormaps.get('tab10').colors\n",
    "import gen_graph as gg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# LEGACY\n",
    "\n",
    "# def hexagon_correction(nodes, connections, size):\n",
    "#     removed_node_indices = []\n",
    "#     skip_index = -1\n",
    "#     for i in range(size[0]):\n",
    "#         # Go through the rows\n",
    "#         skip_index +=1\n",
    "#         for j in range(size[1]):\n",
    "#             # Go through the nodes in the row and remove every third, starting from a different index\n",
    "#             if (j-skip_index)%3 == 0:\n",
    "#                 removed_node_indices.append(i*size[1]+j)    \n",
    "#     nodes = np.delete(nodes, removed_node_indices, axis=0)\n",
    "#     connections = [edge for edge in connections if edge[0] not in removed_node_indices and edge[1] not in removed_node_indices]\n",
    "#     connections = np.array(connections)\n",
    "#     print(removed_node_indices)\n",
    "#     for i in removed_node_indices:\n",
    "#         connections[i-1:] -= 1\n",
    "        \n",
    "#     return nodes, connections\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph(nodes, connections):\n",
    "    '''\n",
    "    Function that plots the graph. It takes the following arguments:\n",
    "    - nodes (arr): The array of nodes\n",
    "    - connections (arr): The array of connections\n",
    "    '''\n",
    "    _,ax = plt.subplots()\n",
    "    ax.plot(nodes[:,0], nodes[:,1], 'ro')\n",
    "    for edge in connections.T:\n",
    "        ax.plot([nodes[edge[0]][0], nodes[edge[1]][0]], [nodes[edge[0]][1], nodes[edge[1]][1]], 'g-')\n",
    "    ax.set_aspect('equal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100\n",
      "200\n",
      "300\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch_geometric as tg\n",
    "import random\n",
    "def load_data(paths):\n",
    "    dataset = []\n",
    "    for path in paths:\n",
    "        graphs = np.load(path)\n",
    "        dataset.extend([tg.data.Data(\n",
    "                        x=torch.tensor(graphs['attr'][i], dtype=torch.float),\n",
    "                        edge_index=torch.tensor(graphs['edges'][i], dtype=torch.int),\n",
    "                        edge_attr=torch.tensor(graphs['edge_attr'][i], dtype=torch.float),\n",
    "                        y=torch.tensor(graphs['y'][i], dtype=torch.float),\n",
    "                        pos=torch.tensor(graphs['coords'][i], dtype=torch.float)  \n",
    "                         ) for i in range(len(graphs['attr']))])\n",
    "        print(len(dataset))\n",
    "        random.shuffle(dataset)\n",
    "    trainable_graphs = int(0.2 * len(dataset))\n",
    "    train_loader = tg.loader.DataLoader(dataset[:trainable_graphs], batch_size=5, shuffle=True)\n",
    "    test_loader = tg.loader.DataLoader(dataset[trainable_graphs:], batch_size=5, shuffle=True)\n",
    "    return train_loader, test_loader\n",
    "train_loader, test_loader = load_data(['graphs/hex.npz', 'graphs/rect.npz', 'graphs/sq.npz'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graph_tg(data: tg.data.Data):\n",
    "    '''\n",
    "    Function that plots the graph. It takes the following arguments:\n",
    "    - a tg.data.Data object\n",
    "    '''\n",
    "    coords = data['pos']\n",
    "    edges = data['edge_index']\n",
    "    _,ax = plt.subplots()\n",
    "    ax.plot(coords[:,0], coords[:,1], 'ro')\n",
    "    ax.plot((coords[:,0][edges[0]], coords[:,0][edges[1]]), (coords[:,1][edges[0]], coords[:,1][edges[1]]), 'g-')\n",
    "    \n",
    "#plot_graph_tg(train_loader.dataset[12])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GCN(\n",
      "  (conv1): GCNConv(1, 4)\n",
      "  (conv2): GCNConv(4, 8)\n",
      "  (classifier): Linear(in_features=8, out_features=3, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "class GCN(torch.nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        torch.manual_seed(12345)\n",
    "        self.conv1 = tg.nn.GCNConv(1, 4)\n",
    "        self.conv2 = tg.nn.GCNConv(4,8)\n",
    "        self.classifier = torch.nn.Linear(8, 3)\n",
    "    def forward(self, x, edge_index, batch):\n",
    "        x = torch.tanh(self.conv1(x, edge_index))\n",
    "        x = self.conv2(x, edge_index)\n",
    "        \n",
    "        x = tg.nn.global_mean_pool(x, batch)\n",
    "        out = torch.nn.functional.softmax(self.classifier(x), dim=1)\n",
    "        \n",
    "        return out\n",
    "model = GCN()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "def train(loader):\n",
    "    model.train()\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)# Perform a single forward pass.\n",
    "        loss = criterion(out, data.y)  # Compute the loss.\n",
    "        #print(loss)\n",
    "        loss.backward()  # Derive gradients.\n",
    "        optimizer.step()  # Update parameters based on gradients.\n",
    "        optimizer.zero_grad() # Reset grads.\n",
    "def test(loader):\n",
    "    model.eval()\n",
    "    correct = 0\n",
    "    for data in loader:\n",
    "        out = model(data.x, data.edge_index, data.batch)\n",
    "        pred = out.argmax(dim=1)  # Use the class with highest probability.\n",
    "        true = data.y.argmax(dim=1)\n",
    "        #print(true)\n",
    "        correct += int((true == pred).sum())\n",
    "    return correct / len(loader.dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 001, Test Accuracy: 0.40000\n",
      "Epoch: 002, Test Accuracy: 0.40000\n",
      "Epoch: 003, Test Accuracy: 0.40000\n",
      "Epoch: 004, Test Accuracy: 0.40000\n",
      "Epoch: 005, Test Accuracy: 0.40000\n",
      "Epoch: 006, Test Accuracy: 0.71667\n",
      "Epoch: 007, Test Accuracy: 0.71667\n",
      "Epoch: 008, Test Accuracy: 0.71667\n",
      "Epoch: 009, Test Accuracy: 0.71667\n",
      "Epoch: 010, Test Accuracy: 0.71667\n",
      "Epoch: 011, Test Accuracy: 0.71667\n",
      "Epoch: 012, Test Accuracy: 0.71667\n",
      "Epoch: 013, Test Accuracy: 0.71667\n",
      "Epoch: 014, Test Accuracy: 0.71667\n",
      "Epoch: 015, Test Accuracy: 0.71667\n",
      "Epoch: 016, Test Accuracy: 0.71667\n",
      "Epoch: 017, Test Accuracy: 0.71667\n",
      "Epoch: 018, Test Accuracy: 0.71667\n",
      "Epoch: 019, Test Accuracy: 0.71667\n",
      "Epoch: 020, Test Accuracy: 0.71667\n",
      "Epoch: 021, Test Accuracy: 0.71667\n",
      "Epoch: 022, Test Accuracy: 0.71667\n",
      "Epoch: 023, Test Accuracy: 0.71667\n",
      "Epoch: 024, Test Accuracy: 0.71667\n",
      "Epoch: 025, Test Accuracy: 0.71667\n",
      "Epoch: 026, Test Accuracy: 0.71667\n",
      "Epoch: 027, Test Accuracy: 0.71667\n",
      "Epoch: 028, Test Accuracy: 0.71667\n",
      "Epoch: 029, Test Accuracy: 0.71667\n",
      "Epoch: 030, Test Accuracy: 0.71667\n",
      "Epoch: 031, Test Accuracy: 0.71667\n",
      "Epoch: 032, Test Accuracy: 0.71667\n",
      "Epoch: 033, Test Accuracy: 0.71667\n",
      "Epoch: 034, Test Accuracy: 0.71667\n",
      "Epoch: 035, Test Accuracy: 0.71667\n",
      "Epoch: 036, Test Accuracy: 0.71667\n",
      "Epoch: 037, Test Accuracy: 0.71667\n",
      "Epoch: 038, Test Accuracy: 0.71667\n",
      "Epoch: 039, Test Accuracy: 0.71667\n",
      "Epoch: 040, Test Accuracy: 0.71667\n",
      "Epoch: 041, Test Accuracy: 0.71667\n",
      "Epoch: 042, Test Accuracy: 0.71667\n",
      "Epoch: 043, Test Accuracy: 0.71667\n",
      "Epoch: 044, Test Accuracy: 0.71667\n",
      "Epoch: 045, Test Accuracy: 0.71667\n",
      "Epoch: 046, Test Accuracy: 0.71667\n",
      "Epoch: 047, Test Accuracy: 0.71667\n",
      "Epoch: 048, Test Accuracy: 0.71667\n",
      "Epoch: 049, Test Accuracy: 0.71667\n",
      "Epoch: 050, Test Accuracy: 0.71667\n",
      "Epoch: 051, Test Accuracy: 0.71667\n",
      "Epoch: 052, Test Accuracy: 0.71667\n",
      "Epoch: 053, Test Accuracy: 0.71667\n",
      "Epoch: 054, Test Accuracy: 0.71667\n",
      "Epoch: 055, Test Accuracy: 0.71667\n",
      "Epoch: 056, Test Accuracy: 0.71667\n",
      "Epoch: 057, Test Accuracy: 0.71667\n",
      "Epoch: 058, Test Accuracy: 0.71667\n",
      "Epoch: 059, Test Accuracy: 0.71667\n",
      "Epoch: 060, Test Accuracy: 0.71667\n",
      "Epoch: 061, Test Accuracy: 0.71667\n",
      "Epoch: 062, Test Accuracy: 0.71667\n",
      "Epoch: 063, Test Accuracy: 0.71667\n",
      "Epoch: 064, Test Accuracy: 0.71667\n",
      "Epoch: 065, Test Accuracy: 0.71667\n",
      "Epoch: 066, Test Accuracy: 0.71667\n",
      "Epoch: 067, Test Accuracy: 0.71667\n",
      "Epoch: 068, Test Accuracy: 0.71667\n",
      "Epoch: 069, Test Accuracy: 0.71667\n",
      "Epoch: 070, Test Accuracy: 0.71667\n",
      "Epoch: 071, Test Accuracy: 0.71667\n",
      "Epoch: 072, Test Accuracy: 0.71667\n",
      "Epoch: 073, Test Accuracy: 0.71667\n",
      "Epoch: 074, Test Accuracy: 0.71667\n",
      "Epoch: 075, Test Accuracy: 0.71667\n",
      "Epoch: 076, Test Accuracy: 0.71667\n",
      "Epoch: 077, Test Accuracy: 0.71667\n",
      "Epoch: 078, Test Accuracy: 0.71667\n",
      "Epoch: 079, Test Accuracy: 0.71667\n",
      "Epoch: 080, Test Accuracy: 0.71667\n",
      "Epoch: 081, Test Accuracy: 0.71667\n",
      "Epoch: 082, Test Accuracy: 0.71667\n",
      "Epoch: 083, Test Accuracy: 0.71667\n",
      "Epoch: 084, Test Accuracy: 0.71667\n",
      "Epoch: 085, Test Accuracy: 0.71667\n",
      "Epoch: 086, Test Accuracy: 0.71667\n",
      "Epoch: 087, Test Accuracy: 0.71667\n",
      "Epoch: 088, Test Accuracy: 0.71667\n",
      "Epoch: 089, Test Accuracy: 0.71667\n",
      "Epoch: 090, Test Accuracy: 0.71667\n",
      "Epoch: 091, Test Accuracy: 0.71667\n",
      "Epoch: 092, Test Accuracy: 0.71667\n",
      "Epoch: 093, Test Accuracy: 0.71667\n",
      "Epoch: 094, Test Accuracy: 0.71667\n",
      "Epoch: 095, Test Accuracy: 0.71667\n",
      "Epoch: 096, Test Accuracy: 0.71667\n",
      "Epoch: 097, Test Accuracy: 0.71667\n",
      "Epoch: 098, Test Accuracy: 0.71667\n",
      "Epoch: 099, Test Accuracy: 0.71667\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(1, 100):\n",
    "    train(train_loader)\n",
    "    acc = test(train_loader)\n",
    "    if epoch % 1 == 0:\n",
    "        print(f'Epoch: {epoch:03d}, Test Accuracy: {acc:.5f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
